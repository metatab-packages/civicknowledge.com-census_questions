{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Questions list\n",
    "\n",
    "Code to create a list of questions based on census metadata, but it may not work, and it costs about $90 in OpenAI credits to tun\n",
    "Probably should use the cache file in the data directory. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import metapack as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display \n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "mp.jupyter.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../data/questions.csv')\n",
    "#df.to_csv('../data/questions.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg = mp.jupyter.open_package()\n",
    "#pkg = mp.jupyter.open_source_package()\n",
    "pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Todo, move this into the metadata. \n",
    "pkg = mp.open_package('index:civicknowledge.com-census_meta-2020e5')\n",
    "paths = pkg.resource('paths').dataframe()\n",
    "mdf = pkg.resource('metadata').dataframe()\n",
    "mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with shelve.open('census_questions') as db:\n",
    "    print(len(db), 'existing records')\n",
    "    print(len(mdf),'column records')\n",
    "    tasks = questions_tasks(mdf)\n",
    "\n",
    "    print(len(tasks),' original tasks')\n",
    "\n",
    "    tasks = [t for t in tasks if t['column_id'] not in db ]\n",
    "    \n",
    "print(len(tasks),' filtered tasks')\n",
    "\n",
    "shuffle(tasks)\n",
    "\n",
    "batches = list(chunked(tasks, 5))\n",
    "\n",
    "print(len(batches), 'batches')\n",
    "\n",
    "print(json.dumps(batches[0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(batch):\n",
    "    \n",
    "    response = write_question(batch)\n",
    "    \n",
    "    tokens_used.append(response['usage']['total_tokens'])\n",
    "\n",
    "    with shelve.open('census_questions') as db:\n",
    "        store_question_responses(task, response, db)\n",
    "\n",
    "\n",
    "from openai.error import ServiceUnavailableError\n",
    "from time import sleep\n",
    "\n",
    "failures_count = 0\n",
    "\n",
    "shuffle(tasks)\n",
    "\n",
    "for task_n, task in enumerate(tqdm(tasks)):\n",
    "    while True:\n",
    "        \n",
    "        if failures_count > 4:\n",
    "            raise Exception(\"Too many failures\")\n",
    "          \n",
    "        failures_count += 1;\n",
    "        \n",
    "        try:\n",
    "            run_batch(task)\n",
    "            failures_count = 0\n",
    "            break\n",
    "        except ServiceUnavailableError as e:       \n",
    "            print(e)\n",
    "            sleep(45)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Batch {task_n} Failed: \", e)\n",
    "            if failures_count == 3:\n",
    "                raise\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
